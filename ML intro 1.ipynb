{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import SVG, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Capacity](#Capacity) <!-- cross-reference: replace spaces/special chars with hyphens -->\n",
    "<font color=blue|red|green|pink|yellow>Text</font> \n",
    "<div class=\"alert alert-block alert-danger\"><b>Hi:</b> Here's some text.</div>\n",
    "<!-- replace alert-xxxx with alert-info for blue box (tips & notes), alert-warning for yellow (examples, equations), alert-success for green (sectional summaries & similar), alert-danger for red (serious warnings/issues; use sparingly) -->\n",
    "<span class=\"badge badge-secondary\">New</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"jumbotron jumbotron-fluid\">\n",
    "  <div class=\"container\">\n",
    "    <h1 class=\"display-4\">Machine Learning</h1>\n",
    "    <h2 class=\"display-4\">Introduction: Part I</h1>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Start with some appetizers. \n",
    "- Detectron.\n",
    "- GANs.\n",
    "- VAEs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Course details?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "- Focus on philosophy, principles, and overall process (mental models for thinking about ML) rather than specific methods or deeply worked examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='./img/danger.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is learning?\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Improving <i>performance</i> (P) on some class of <i>tasks</i> (T) given <i>experience</i> (E).</b>\n",
    "</div>\n",
    "(citation) \n",
    "\n",
    "$\\rightarrow$ thus a process of _optimization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It's not obvious what these things are, though you might think of specific examples. \n",
    "Let's start from the bottom up, from first principles of learning to more complex ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evolution\n",
    "  - Process of optimization\n",
    "    - Chemical thermodynamics, metastability\n",
    "  - Chemical to cellular to multicellular to nervous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Statistical? learning\n",
    "  - Correlational, acausal\n",
    "  - Stereotyped/predictable responses\n",
    "  - Kalman filter\n",
    "    - Will more or less keep track of a noisy process, but in its basic form can't learn causal relationships controlling the patterns it \"experiences\" in the dynamics.\n",
    "  - Circadian entrainment\n",
    "    - Relationship to higher decision processes\n",
    "  - Single neuron? PFC damage example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Causal structure learning\n",
    "  - Abstractions: not only how a single movement will reach a single blueberry, but how fitness in general improves movements (including blueberry-related movements), and how thinking positively about fitness improves idea-generation about better achieving fitness, etc.\n",
    "  - Planning and design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Invariance, transformations, and abstraction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Reinforcement learning\n",
    "  - Structured expectations.\n",
    "  - What outcomes are being considered? How is performance being \"measured\"?\n",
    "    - Humans: evolutionary and social (mostly para-evolutionary?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "- Definitions: Programs, algorithms, and processes (stochasticity?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It's easy enough to think of models as black boxes that take some input and provide a desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-1.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "[Blueberry example? Artificial tasks/setup conditions, ]\n",
    "\n",
    "However, it's also easy to compare ML systems to human brains. But how can we interpret brains in terms of Fig 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Brains, and the scope of ML\n",
    "\n",
    "- \"Learning itself is not the task\": not so for brain. Brain is \"agent\". \n",
    "\n",
    "- ML systems are situated in human decisions: their outputs influence their inputs ~only through human decisions, not because they are optimizing for evolutionary outcomes.\n",
    "- Outcome level: designed vs. evolved\n",
    "  - brains need to solve total RL problem (ultimately no supervision)\n",
    "  - online and recursive (brain)\n",
    "- Horizon\n",
    "- Diagrams? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-2.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A useful metaphor, if you don't have a strong intuition for what \"model\" means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-3.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- This is still a huge oversimplification. \n",
    "- At best, it can apply for a single instant in time, the smallest of decisions. \n",
    "- Our brains make predictions within predictions; not only predictions about grabbing the current blueberry, but about the value of blueberry picking as an activity, about my arm getting tired... [think of better examples]\n",
    "- What is \"everything else\"? Where do we draw the boundary? Cortex vs brain stem vs spinal cord vs... The muscle is \"everything else\", on a short time scale. Metabolic control. Environmental manipulation (boundary drawn outside the body; smart phones). If we consider chemical evolution, the model and the modelled are the same thing; there is only a series of states.\n",
    "- Really, the brain and body are a complicated tangle of such reciprocal relationships between parts, all balancing to produce complex behaviour that achieves, in general, something that looks like the preceding diagrams: at each level, predictions are more or less successful enough to satisfy certain constraints (evolutionary or designed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "You can mostly stick to this figure for now, and most ML models are simple enough or have well-defined inputs and outputs, and the \"model\" can be treated as a mathematical function or set of functions.\n",
    "However, the state of the art in ML is largely about learning to learn (or meta-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-1.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-4.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe change the one below slightly: interested in how the output AND input are used to decide how to update the system. Doesn't need to look like \"all movement immediately alters the environment\" (model can be more abstract without being simplistic.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src='./img/learning-5.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML vs statistics\n",
    "- Procedures/\"statistics\" vs. optimization\n",
    "- Human decisions: in the past (e.g. which statistics to use) vs. deferred in the present (e.g. which learning assumptions to make)\n",
    "- Simpler vs. more complex ML models?\n",
    "  - Deep learning: automatically find structure given high-level constraints, instead of assuming which statistics are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philosophy summary?\n",
    "- ML is about optimizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Improving <i>performance</i> (P) on some class of <i>tasks</i> (T) given <i>experience</i> (E).</b>\n",
    "</div>\n",
    "(citation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The task, *T*\n",
    "- ML systems considered as processing _examples_ composed of _features_\n",
    "  - Typically an example is represented as a vector $\\mathbf{x}\\in\\mathbb{R}^n$ with $n$ features\n",
    "\\begin{equation*}\n",
    "f:\\mathbb{R}^n\\rightarrow ?\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Which of $k$ categories does an input belong to?\n",
    "<br><br>\n",
    "\\begin{equation*}\n",
    "f:\\mathbb{R}^n\\rightarrow\\{1,\\dots,k\\}\n",
    "\\end{equation*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May also output distribution over classes\n",
    "- Missing values (learn *set* of functions): common in medical applications\n",
    "- Anomaly detection (e.g. spam, credit card fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MNIST (figure)\n",
    "- What it *doesn't* do: understand numbers or math. Only shapes. This is all it learns, to satisfy its constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Example: CNN architecture. \n",
    "Explanation: constrain with simple principle (location invariance: convolutions) but don't impose a human-decided set of calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification in neuroscience\n",
    "- Classify neuron type from electrophysiology data\n",
    "- Classify disease state from neuroimaging data (e.g. tumour in structural MRI)\n",
    "- Predict behavioural class (e.g. \"currently reaching\" vs. \"resting\") from brain measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regression\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "What value (of some quantity) is associated with a given input?\n",
    "<br><br>\n",
    "\\begin{equation*}\n",
    "f:\\mathbb{R}^n\\rightarrow\\mathbb{R}\n",
    "\\end{equation*}\n",
    "</div>\n",
    "- Examples:\n",
    "  - Neuroscience:\n",
    "    - Predict *level*/*quantity*: firing rate, survival time, gene expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Structured output\n",
    "- Output is a vector or some other structure with relationships between members.\n",
    "- Subsumes all other mapping tasks, though typically not applied to the well-known cases given above.\n",
    "- Examples:\n",
    "  - Partition of input (e.g. superpixels)\n",
    "  - Image captioning (sentence describing image)\n",
    "  - Parsing sentences into a tree describing grammatical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The Deep Learning book gives a bunch of other examples..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transcription, translation\n",
    "- Transcription: Observe a relatively unstructured representation and transcribe into discrete, textual form. \n",
    "  - e.g. OCR, speech recognition\n",
    "- Translation: Sequence of symbols in one language to sequence of symbols in another language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Synthesis and sampling\n",
    "- Output is a newly generated example that is *similar* to the training data.\n",
    "- Like structured output, but without a single correct output for each (implicit distribution).\n",
    "- Examples\n",
    "  - Generate audio for given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Missing value imputation\n",
    "- $\\mathbf{x}\\in\\mathbb{R}^n$ with some $x_i$ missing\n",
    "- Compare to sampling (partial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Denoising\n",
    "- Predict clean example $\\mathbf{x}\\in\\mathbb{R}^n$ given a corrupted example $\\tilde{\\mathbf{x}}\\in\\mathbb{R}^n$.\n",
    "- Unknown corruption process; i.e. learn $p(\\mathbf{x}|\\tilde{\\mathbf{x}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probability mass/density estimation\n",
    "- Implicitly subsumes other tasks\n",
    "  - once we have explicitly obtained $p(\\mathbf{x})$ we can perform the other tasks as well (e.g. missing value imputation).\n",
    "  - e.g. a generative model that produces samples, and half the samples it produces belong in a certain category A; implicitly, the behaviour of the model says p(A)=0.5\n",
    "- $p_\\mathrm{model}:\\mathbb{R}^n\\rightarrow\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others\n",
    "- Causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The performance measure, $P$\n",
    "- Quantitative\n",
    "- Usually task-specific (clarify)\n",
    "- Choice not obvious: penalize frequent small mistakes or infrequent large mistakes? Global vs. local errors?\n",
    "- Accuracy and error rate (expected 0-1 loss)\n",
    "- Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The experience, $E$\n",
    "- Datasets: collections of many examples/data points\n",
    "- Design matrix\n",
    "  - e.g. $\\mathit{\\mathbf{X}}\\in\\mathbb{R}^{150\\times4}$ for irises (150 examples, 4 features). $X_{i,1}$ is the sepal length of plant $i$.\n",
    "  - Not always possibly; some data (e.g. images of different sizes) are heterogeneous and are described as sets instead of matrices: $\\{\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\dots,\\mathbf{x}^{(m)}\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unsupervised learning\n",
    "- Experience a dataset with many features and learn useful structural properties\n",
    "- Typically want to learn the entire probability distribution that generated the dataset (explicitly or not)\n",
    "- Learn $p(\\mathbf{x})$ from $\\mathbf{x}$ examples.\n",
    "- e.g. clustering: model learns to produce a partitioning that transforms the input according to certain principles embodied by the model and the learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised learning\n",
    "- Each example experienced is associated with a label or target.\n",
    "  - Labels may be simple numbers (e.g. class numbers) or more complex (e.g. correctly transcribed sentence).\n",
    "- Learn $p(\\mathbf{y}|\\mathbf{x})$ from $(\\mathbf{x},\\mathbf{y})$ examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised vs. unsupervised\n",
    "- Given the chain rule, an unsupervised problem may be decomposed into $n$ supervised problems: \n",
    "$$p(\\mathbf{x})=\\prod_{i=1}^{n}p(\\mathrm{x}_i|\\mathrm{x}_1,\\dots,\\mathrm{x}_{i-1})$$\n",
    "- By the definition of the conditional density, a supervised problem may be solved by unsupervised learning of the joint distribution:\n",
    "$$p(y|\\mathbf{x})=\\frac{p(\\mathbf{x},y)}{\\sum_{y^\\prime}p(\\mathbf{x},y^\\prime)}$$\n",
    "- In any case, these terms help to roughly categorize problems. Traditionally, regression, classification, and structured output are considered supervised; density estimation is considered unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Other paradigms\n",
    "- Semi-supervised (only some example labelled)\n",
    "- Multi-instance (entire collections of examples labelled)\n",
    "- Reinforcement learning (environment; feedback between learning system and experiences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization\n",
    "- Connect to \"the experience\"\n",
    "- Practical concerns. Stochasticity and local minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalization\n",
    "- How does a model perform on previously unseen inputs?\n",
    "  - Example: Different coloured cat than in training examples.\n",
    "- Training error vs. test/generalization error\n",
    "- Difficulty: only get to observe training set (?).\n",
    "- Data generating process: Assumption that training and test examples are identically distributed, and individual examples are independent of each other --> allows the generating process to be modeled as a distribution over a single example.\n",
    "  - Refer to shared underlying distribution as *data generating distribution* or $p_\\mathrm{data}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Underfitting and overfitting\n",
    "1. Make the training error small\n",
    "2. Make the gap between training and test error small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Capacity\n",
    "- Ability of a model to fit a wide variety of functions. \n",
    "- Often controlled by choosing the *hypothesis space* of functions the learning algorithm can select as solutions.\n",
    "- Representational capacity (i.e. how well the chosen class of functions could solve the problem) vs. effective capacity (i.e. given additional limitations, such as imperfection of optimization process, how well can chosen method solve the problem? upper bound is representational capacity).\n",
    "- Often considered in terms of number of parameters... but not all parameters are equal (VC dimension: \"the largest possible value of $m$ for which there exists a training set of $m$ different examples that the classifier can label arbitrarily\").\n",
    "- Too high: overfitting. Too low: underfitting. Figure 5.2.\n",
    "- Statistical learning theory: Gap between training and generalization error is bounded above by a quantity that grows with capacity, but shrinks with number of training examples.\n",
    "  - Simpler functions more likely to generalize, but must still choose a sufficiently complex hypothesis to achieve low training error.\n",
    "- Performance is typically best when model capacity is appropriate for the complexity of the task and the number of available examples.\n",
    "- Example:\n",
    "  - Quadratic has higher capacity than linear.\n",
    "  - Pathological example (single-parameter universal approximator).\n",
    "- Ideal model: Oracle that knows the true distribution.\n",
    "  - May still make errors; e.g. due to noise inherent to generating distribution, or due to excluded variables involved in the deterministic relationship between $\\mathbf{x}$ and $y$.\n",
    "  - *Bayes error*: error incurred by an oracle. That is, the lower bound on the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Capacity\n",
    "#### \"Number of parameters\"\n",
    "$$f_\\theta(x)=\\sin^2\\left(2^{rx}\\arcsin\\sqrt{\\theta}\\right)$$\n",
    "<img src='./img/single-param.png'>\n",
    "(Piantadosi, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Non-parametric models\n",
    "- Limit of infinite capacity; no parametrized function fixed prior to learning.\n",
    "- Example: \n",
    "  - Nearest neighbour regression.\n",
    "  - Wrap parametric learning algorithm inside another algorithm that optimizes no. of parameters as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### No Free Lunch theorem\n",
    "\"averaged over all possible data generating distributions, every classification algorithm has the same error rate when classifying previously unobserved points\"\n",
    "i.e. we need to make assumptions about which data generating distributions are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classes of models/learning\n",
    "- Venn diagram? (Fig 1.4)\n",
    "- Deep learning vs. classic/rule-based systems (Fig 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularization\n",
    "- Any modification to learning algorithm intended to reduce generalization error but not training error.\n",
    "- Additional preferences/penalties about the hypothesis space, above simple inclusion/exclusion.\n",
    "- e.g. weight decay, $J(\\mathbf{w})=\\mathrm{MSE_{train}}+\\lambda\\mathbf{w}^\\top\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "- Learning algorithm settings; not adapted by learning algorithm itself\n",
    "- e.g. the degree of the polynomial in polynomial regression; $\\lambda$ for weight decay\n",
    "- Can't optimize on training set; would always optimize for higher capacity\n",
    "  - Need a *validation set* (**not** overlapping with test set)\n",
    "  - Split training set into 80%/20% training/validation\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "- Split dataset into $k$ non-overlapping subsets\n",
    "- $k$ trials; on trial $i$, use $i$-th subset as test set and remainder as training set. Overall test error is average of trial test errors.\n",
    "- Unfortunately there are no unbiased estimators of the variance of such average error estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point estimators\n",
    "i.e. \"statistics\"\n",
    "- What is the \"best\" prediction for a quantity of interest? (a number or vector)\n",
    "  - e.g. weights in linear regression\n",
    "- Any function of i.i.d. data points $\\{\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(m)}\\}$: $$\\hat{\\mathbf{\\theta}}_m=g\\left(\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(m)}\\right)$$\n",
    "- Good estimator has $\\hat{\\mathbf{\\theta}}$ close to underlying $\\mathbf{\\theta}$\n",
    "- Frequentist perspective: true value $\\mathbf{\\theta}$ is fixed but unknown, and $\\hat{\\mathbf{\\theta}}$ is function of the data; as the data is drawn from a random process, $\\hat{\\mathbf{\\theta}}$ is a random variable.\n",
    "- Note: function estimation: approximate some function $f$ with a model or estimate $\\hat{f}$; this is fundamentally the same as parameter estimation, except the point estimate is in function space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias\n",
    "$$\\mathrm{bias}\\left(\\hat{\\mathbf{\\theta}}_m\\right)=\\mathbb{E}\\left(\\hat{\\mathbf{\\theta}}_m\\right)-\\mathbf{\\theta}$$\n",
    "- Expectation over the data.\n",
    "- Unbiased: $\\mathrm{bias}=0$, i.e. $\\mathbb{E}(\\hat{\\mathbf{\\theta}}_m)=\\mathbf{\\theta}$\n",
    "  - Asymptotically unbiased if $\\lim_{m\\rightarrow\\infty}\\mathrm{bias}(\\hat{\\mathbf{\\theta}}_m)$\n",
    "e.g. Bernoulli distribution, Guassian mean (see book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "$$\\mathrm{Var}(\\hat\\theta)$$\n",
    "- Square root of variance: standard error, $\\mathrm{SE}(\\hat{\\theta})$\n",
    "- Expected variation in estimate as we independently resample the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias-variance tradeoff\n",
    "\\begin{align*}\n",
    "\\mathrm{MSE}&=\\mathbb{E}\\left[(\\hat{\\theta}_m-\\theta)^2\\right] \\\\\n",
    "            &=\\mathrm{Bias}(\\hat{\\theta}_m)^2+\\mathrm{Var}(\\hat{\\theta}_m)\n",
    "\\end{align*}\n",
    "- Figure 5.6\n",
    "- Typically use cross-validation; may also compare MSE directly\n",
    "  - MSE: Overall expected deviation\n",
    "  - Increasing capacity tends to increase variance and decrease bias\n",
    "  - Small MSE: estimator keeping both bias and variance somewhat in check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representation, causality\n",
    "- Disentangling factors of variation (e.g. PCA limitations)\n",
    "- Separability vs. representation (e.g. polar vs cartesian)\n",
    "- Another example: brain disentangling object state from illumination, perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"What makes a good model\"\n",
    "Get a list (CoSMo paper?) and see if I can improve integration of the slides with these ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "- Be careful what assumptions you make, and what you *provide* for your models:\n",
    "  - Inputs: structure, processing/calculations/statistics \n",
    "  - Functional capacity\n",
    "  - Regularization or other constraints to improve generalization\n",
    "  - Resource capacity\n",
    "- Focus on learning to balance capacity, amount of available data/examples, with the use of \n",
    "  - test sets\n",
    "  - cross-validation\n",
    "  - regularization"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
