{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Goodfellow ~Ch 5.1-5.4\n",
    "- Learning algorithms\n",
    "- Capacity, overfitting, underfitting\n",
    "- Hyperparameters & validation sets\n",
    "- Estimators, bias, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is learning?\n",
    "- Performance (P) improves given experience (E) with tasks in some class of tasks (T)\n",
    "- Learning is not the task, but the process that enables performance on the task (limitations)\n",
    "- Definitions: Programs, algorithms, and processes (stochasticity?)\n",
    "- ML systems considered as processing _examples_ composed of _features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Classification\n",
    "- Which of $k$ categories does an input belong to?\n",
    "- $f:\\mathbb{R}^n\\rightarrow\\{1,\\dots,k\\}$\n",
    "- May also output distribution over classes\n",
    "- Missing values (learn *set* of functions): common in medical applications\n",
    "- Examples: \n",
    "  - MNIST (figure)\n",
    "  - Anomaly detection (e.g. spam, credit card fraud)\n",
    "  - Neuroscience:\n",
    "    - Classify neuron type from electrophysiology data\n",
    "    - Classify disease state from neuroimaging data (e.g. tumour in structural MRI)\n",
    "    - Predict behavioural class (e.g. \"currently reaching\" vs. \"resting\") from brain measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regression\n",
    "- What value of a quantity is associated with a given input?\n",
    "- $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$\n",
    "- Examples:\n",
    "  - Neuroscience:\n",
    "    - Predict *level*/*quantity*: firing rate, survival time, gene expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Structured output\n",
    "- Output is a vector or some other structure with relationships between members.\n",
    "- Subsumes all other mapping tasks, though typically not applied to the well-known cases given above.\n",
    "- Examples:\n",
    "  - Partition of input (e.g. superpixels)\n",
    "  - Image captioning (sentence describing image)\n",
    "  - Parsing sentences into a tree describing grammatical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Transcription, translation\n",
    "- Transcription: Observe a relatively unstructured representation and transcribe into discrete, textual form. \n",
    "  - e.g. OCR, speech recognition\n",
    "- Translation: Sequence of symbols in one language to sequence of symbols in another language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Synthesis and sampling\n",
    "- Output is a newly generated example that is *similar* to the training data.\n",
    "- Like structured output, but without a single correct output for each (implicit distribution).\n",
    "- Examples\n",
    "  - Generate audio for given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Missing value imputation\n",
    "- $\\mathbf{x}\\in\\mathbb{R}^n$ with some $x_i$ missing\n",
    "- Compare to sampling (partial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Denoising\n",
    "- Predict clean example $\\mathbf{x}\\in\\mathbb{R}^n$ given a corrupted example $\\tilde{\\mathbf{x}}\\in\\mathbb{R}^n$.\n",
    "- Unknown corruption process; i.e. learn $p(\\mathbf{x}|\\tilde{\\mathbf{x}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Probability mass/density estimation\n",
    "- Implicitly subsumes other tasks, and once we have explicitly obtained $p(\\mathbf{x})$ we can perform the other tasks as well (e.g. missing value imputation).\n",
    "- $p_\\mathrm{model}:\\mathbb{R}^n\\rightarrow\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The performance measure, $P$\n",
    "- Quantitative\n",
    "- Usually task-specific (clarify)\n",
    "- Choice not obvious: penalize frequent small mistakes or infrequent large mistakes? Global vs. local errors?\n",
    "- Accuracy and error rate (expected 0-1 loss)\n",
    "- Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The experience, $E$\n",
    "- Datasets: collections of many examples/data points\n",
    "- Design matrix\n",
    "  - e.g. $\\mathit{\\mathbf{X}}\\in\\mathbb{R}^{150\\times4}$ for irises (150 examples, 4 features). $X_{i,1}$ is the sepal length of plant $i$.\n",
    "  - Not always possibly; some data (e.g. images of different sizes) are heterogeneous and are described as sets instead of matrices: $\\{\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\dots,\\mathbf{x}^{(m)}\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Unsupervised learning\n",
    "- Experience a dataset with many features and learn useful structural properties\n",
    "- Typically want to learn the entire probability distribution that generated the dataset (explicitly or not)\n",
    "- Learn $p(\\mathbf{x})$ from $\\mathbf{x}$ examples.\n",
    "- e.g. clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Supervised learning\n",
    "- Each example experienced is associated with a label or target.\n",
    "  - Labels may be simple numbers (e.g. class numbers) or more complex (e.g. correctly transcribed sentence).\n",
    "- Learn $p(\\mathbf{y}|\\mathbf{x})$ from $(\\mathbf{x},\\mathbf{y})$ examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Supervised vs. unsupervised\n",
    "- Given the chain rule, an unsupervised problem may be decomposed into $n$ supervised problems: \n",
    "$$p(\\mathbf{x})=\\prod_{i=1}^{n}p(\\mathrm{x}_i|\\mathrm{x}_1,\\dots,\\mathrm{x}_{i-1})$$\n",
    "- By the definition of the conditional density, a supervised problem may be solved by unsupervised learning of the joint distribution:\n",
    "$$p(y|\\mathbf{x})=\\frac{p(\\mathbf{x},y)}{\\sum_{y^\\prime}p(\\mathbf{x},y^\\prime)}$$\n",
    "- In any case, these terms help to roughly categorize problems. Traditionally, regression, classification, and structured output are considered supervised; density estimation is considered unsupervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Other paradigms\n",
    "- Semi-supervised (only some example labelled)\n",
    "- Multi-instance (entire collections of examples labelled)\n",
    "- Reinforcement learning (environment; feedback between learning system and experiences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization\n",
    "- Connect to \"the experience\"\n",
    "- Practical concerns. Stochasticity and local minima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generalization\n",
    "- How does a model perform on previously unseen inputs?\n",
    "  - Example: Different coloured cat than in training examples.\n",
    "- Training error vs. test/generalization error\n",
    "- Difficulty: only get to observe training set (?).\n",
    "- Data generating process: Assumption that training and test examples are identically distributed, and individual examples are independent of each other --> allows the generating process to be modeled as a distribution over a single example.\n",
    "  - Refer to shared underlying distribution as *data generating distribution* or $p_\\mathrm{data}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Underfitting and overfitting\n",
    "1. Make the training error small\n",
    "2. Make the gap between training and test error small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Capacity\n",
    "- Ability of a model to fit a wide variety of functions. \n",
    "- Often controlled by choosing the *hypothesis space* of functions the learning algorithm can select as solutions.\n",
    "- Representational capacity (i.e. how well the chosen class of functions could solve the problem) vs. effective capacity (i.e. given additional limitations, such as imperfection of optimization process, how well can chosen method solve the problem? upper bound is representational capacity).\n",
    "- Often considered in terms of number of parameters... but not all parameters are equal (VC dimension: \"the largest possible value of $m$ for which there exists a training set of $m$ different examples that the classifier can label arbitrarily\").\n",
    "- Too high: overfitting. Too low: underfitting. Figure 5.2.\n",
    "- Statistical learning theory: Gap between training and generalization error is bounded above by a quantity that grows with capacity, but shrinks with number of training examples.\n",
    "  - Simpler functions more likely to generalize, but must still choose a sufficiently complex hypothesis to achieve low training error.\n",
    "- Performance is typically best when model capacity is appropriate for the complexity of the task and the number of available examples.\n",
    "- Example:\n",
    "  - Quadratic has higher capacity than linear.\n",
    "  - Pathological example (single-parameter universal approximator).\n",
    "- Ideal model: Oracle that knows the true distribution.\n",
    "  - May still make errors; e.g. due to noise inherent to generating distribution, or due to excluded variables involved in the deterministic relationship between $\\mathbf{x}$ and $y$.\n",
    "  - *Bayes error*: error incurred by an oracle. That is, the lower bound on the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Non-parametric models\n",
    "- Limit of infinite capacity; no parametrized function fixed prior to learning.\n",
    "- Example: \n",
    "  - Nearest neighbour regression.\n",
    "  - Wrap parametric learning algorithm inside another algorithm that optimizes no. of parameters as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### No Free Lunch theorem\n",
    "\"averaged over all possible data generating distributions, every classification algorithm has the same error rate when classifying previously unobserved points\"\n",
    "i.e. we need to make assumptions about which data generating distributions are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Regularization\n",
    "- Any modification to learning algorithm intended to reduce generalization error but not training error.\n",
    "- Additional preferences/penalties about the hypothesis space, above simple inclusion/exclusion.\n",
    "- e.g. weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representation, causality\n",
    "- Disentangling factors of variation (e.g. PCA limitations)\n",
    "- Separability vs. representation (e.g. polar vs cartesian)\n",
    "- Another example: brain disentangling object state from illumination, perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classes of models/learning\n",
    "- Venn diagram? (Fig 1.4)\n",
    "- Deep learning vs. classic/rule-based systems (Fig 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VC dimension and capacity: single-parameter counterexample"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
